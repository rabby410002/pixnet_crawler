# pixnet_crawler
* tryproxy.py
將可用的proxy存到pickle檔
* search_result.py
第一支爬蟲:將搜尋結果列表萃取出並結構化欄位存到mysql
* update_content.py
第二支爬蟲:更新content欄位


# Extract columns
* fill_reviewid.py
萃取文章id
* extract_prod2.py
萃取產品
